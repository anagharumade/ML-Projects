{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('C:/Users/Anagha Rumade/Documents/Python Scripts/TensorFlow')\n",
    "Images_dir = os.path.join(root_dir, 'Images')\n",
    "\n",
    "print(os.path.exists(root_dir))\n",
    "print(os.path.exists(Images_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = pd.read_csv(root_dir + '/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one of the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.choice(train_data_labels.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(Images_dir, 'train', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(image)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking all the Input Images in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_images = []\n",
    "for img_name in train_data_labels.filename:\n",
    "    filepath = os.path.join(Images_dir, 'train', img_name)\n",
    "    image = imageio.imread(filepath)\n",
    "    image = image.astype('float32')\n",
    "    all_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 618 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_x = np.stack(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_data_labels[:split_size], train_data_labels[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Neurons in every layer\n",
    "num_neurons_input = 28*28\n",
    "num_neurons_output = 10\n",
    "num_neurons_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, num_neurons_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_neurons_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variables\n",
    "epoch = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_input, num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_hidden, num_neurons_output]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-55fd29c738f5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, ).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(batch_normalize):\n",
    "    batch_temp = batch_normalize/batch_normalize.max()\n",
    "    return batch_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = np.random.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, num_neurons_input)\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    batch_y = eval(dataset_name).ix[batch_mask, 'label'].values\n",
    "    batch_y = dense_to_one_hot(batch_y)\n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

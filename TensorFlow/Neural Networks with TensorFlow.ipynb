{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('C:/Users/Anagha Rumade/Documents/Python Scripts/TensorFlow')\n",
    "Images_dir = os.path.join(root_dir, 'Images')\n",
    "\n",
    "print(os.path.exists(root_dir))\n",
    "print(os.path.exists(Images_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = pd.read_csv(root_dir + '/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one of the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rng.choice(train_data_labels.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(Images_dir, 'train', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(image)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking all the Input Images in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_images = []\n",
    "for img_name in train_data_labels.filename:\n",
    "    filepath = os.path.join(Images_dir, 'train', img_name)\n",
    "    image = imageio.imread(filepath)\n",
    "    image = image.astype('float32')\n",
    "    all_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.]],\n",
       "\n",
       "       [[  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.]],\n",
       "\n",
       "       [[  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.]],\n",
       "\n",
       "       [[  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.]],\n",
       "\n",
       "       [[  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.],\n",
       "        [  0.,   0.,   0., 255.]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 901 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_x = np.stack(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the data shape is something as follows:\n",
    "<br>34300 Rows\n",
    "<br>28 columns\n",
    "<br>28 height dimension columns\n",
    "<br>and 4 elements in each of these\n",
    "\n",
    "Something like a cube structure but more rectangular with each little cube in the structure holding 4 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_data_labels[:split_size], train_data_labels[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Neurons in every layer\n",
    "num_neurons_input = 28*28\n",
    "num_neurons_output = 10\n",
    "num_neurons_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, num_neurons_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_neurons_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variables\n",
    "epoch = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_input, num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_hidden, num_neurons_output]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Neural Networks Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x/train_x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(batch_normalize):\n",
    "    batch_temp = batch_normalize/batch_normalize.max()\n",
    "    return batch_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does .reshape(-1, (28*28)) do?<br>\n",
    "It creates an array compatible with the previous shape. -1 gives python the liberty to create its own number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x[[rng.choice(train_x.shape[0],5)]].reshape(-1, (28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, num_neurons_input)\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    batch_y = eval(dataset_name + '_y').loc[batch_mask, 'label'].values\n",
    "    batch_y = dense_to_one_hot(batch_y)\n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a session and running it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be broadcastable: logits_size=[512,10] labels_size=[128,10]\n\t [[{{node softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_1, softmax_cross_entropy_with_logits/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_with_logits', defined at:\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-8223c7662f12>\", line 1, in <module>\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=y))\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1888, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 7747, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[512,10] labels_size=[128,10]\n\t [[{{node softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_1, softmax_cross_entropy_with_logits/Reshape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[512,10] labels_size=[128,10]\n\t [[{{node softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_1, softmax_cross_entropy_with_logits/Reshape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5c98e8961366>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[0;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[512,10] labels_size=[128,10]\n\t [[{{node softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_1, softmax_cross_entropy_with_logits/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_with_logits', defined at:\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-8223c7662f12>\", line 1, in <module>\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=y))\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1888, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 7747, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Anagha Rumade\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[512,10] labels_size=[128,10]\n\t [[{{node softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_1, softmax_cross_entropy_with_logits/Reshape_1)]]\n"
     ]
    }
   ],
   "source": [
    "#Initializing the session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoc in range(epoch):\n",
    "        avg_cost = 0\n",
    "        all_batches = int(train_x.shape[0]/batch_size)\n",
    "        for batch in range(all_batches):\n",
    "            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train')\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "            avg_cost += c/all_batches\n",
    "\n",
    "        print('Epoch:' + (epoch+1) + ' cost: ' + avg_cost)\n",
    "\n",
    "    print('Training Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

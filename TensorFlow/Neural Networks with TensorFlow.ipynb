{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('C:/Users/Anagha Rumade/Documents/Python Scripts/TensorFlow')\n",
    "Images_dir = os.path.join(root_dir, 'Images')\n",
    "\n",
    "print(os.path.exists(root_dir))\n",
    "print(os.path.exists(Images_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = pd.read_csv(root_dir + '/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one of the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.choice(train_data_labels.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(Images_dir, 'train', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(image)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking all the Input Images in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_images = []\n",
    "for img_name in train_data_labels.filename:\n",
    "    filepath = os.path.join(Images_dir, 'train', img_name)\n",
    "    image = imageio.imread(filepath)\n",
    "    image = image.astype('float32')\n",
    "    all_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_x = np.stack(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_data_labels[:split_size], train_data_labels[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Neurons in every layer\n",
    "num_neurons_input = 28*28\n",
    "num_neurons_output = 10\n",
    "num_neurons_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, num_neurons_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_neurons_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variables\n",
    "epoch = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_input, num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_hidden, num_neurons_output]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Neural Networks Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-55fd29c738f5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, ).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(batch_normalize):\n",
    "    batch_temp = batch_normalize/batch_normalize.max()\n",
    "    return batch_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = np.random.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, num_neurons_input)\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    batch_y = eval(dataset_name).ix[batch_mask, 'label'].values\n",
    "    batch_y = dense_to_one_hot(batch_y)\n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

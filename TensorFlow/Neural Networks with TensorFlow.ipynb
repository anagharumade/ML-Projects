{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('C:/Users/Anagha Rumade/Documents/Python Scripts/TensorFlow')\n",
    "Images_dir = os.path.join(root_dir, 'Images')\n",
    "\n",
    "print(os.path.exists(root_dir))\n",
    "print(os.path.exists(Images_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = pd.read_csv(root_dir + '/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one of the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rng.choice(train_data_labels.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(Images_dir, 'train', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(image)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking all the Input Images in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_images = []\n",
    "for img_name in train_data_labels.filename:\n",
    "    filepath = os.path.join(Images_dir, 'train', img_name)\n",
    "    image = imageio.imread(filepath)\n",
    "    image = image.astype('float32')\n",
    "    all_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_x = np.stack(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_data_labels[:split_size], train_data_labels[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Neurons in every layer\n",
    "num_neurons_input = 28*28\n",
    "num_neurons_output = 10\n",
    "num_neurons_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, num_neurons_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_neurons_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variables\n",
    "epoch = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_input, num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_hidden, num_neurons_output]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([num_neurons_hidden])),\n",
    "    'output': tf.Variable(tf.random_normal([num_neurons_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Neural Networks Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-55fd29c738f5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, ).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(batch_normalize):\n",
    "    batch_temp = batch_normalize/batch_normalize.max()\n",
    "    return batch_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, num_neurons_input)\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    batch_y = eval(dataset_name + '_y').ix[batch_mask, 'label'].values\n",
    "    batch_y = dense_to_one_hot(batch_y)\n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a session and running it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c98e8961366>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Initializing the session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#Initializing the session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoc in range(epoch):\n",
    "        avg_cost = 0\n",
    "        all_batches = int(train_x.shape[0]/batch_size)\n",
    "        for batch in range(all_batches):\n",
    "            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train')\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "            avg_cost += c/all_batches\n",
    "\n",
    "        print('Epoch:' + (epoch+1) + ' cost: ' + avg_cost)\n",
    "\n",
    "    print('Training Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
